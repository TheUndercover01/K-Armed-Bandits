{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c826288-24b1-40db-a6c3-dad88157de8c",
   "metadata": {},
   "source": [
    "The king needs our help. He has participated in a RC car competetion, and he has 5 cars to choose from. This is no ordinary RC car race it is a probabilistic one where each car move a random distance based on a set normal distribution(with standard deviation 1 and different means ) at each time step. The king has 5 cars to choose from but he has no idea what distribution do those car hold. He obviously cant test all cars at once(he can only control one car at a time), as he dosent trust anyone with his cars he asks us to find a way to test them and find the best car. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04040ead-2828-4dcb-a94f-e31e3080cba0",
   "metadata": {},
   "source": [
    "We can solve this using K-armed bandit problem where at each time step the distance travelled by the car is the reward received and our job is to maximize reward at each time step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3643d889-c9cf-44b6-96a2-ca235292cd1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pybullet build time: Dec 17 2023 23:51:54\n"
     ]
    }
   ],
   "source": [
    "import pybullet as p\n",
    "import time\n",
    "import numpy as np\n",
    "import pybullet_data \n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4750f4f8-e956-4236-a1b6-932e47a15452",
   "metadata": {},
   "source": [
    "For each of the car we need a distribution by which the car moves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f4aeb-0470-4263-ae4d-ece06957f9a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fc3200-5731-42cd-b80d-7bf7927a1b2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71738494, 0.78389933, 1.22702457, 1.1928157 , 1.09944582])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = 5\n",
    "means = np.random.normal(1 , 0.4 , cars)\n",
    "means # All have standard deviarion 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308591ff-3d78-4122-94b2-1fab5a9c5657",
   "metadata": {},
   "source": [
    "We will be employing Optimistic initial values and sample avereging technique "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9534fd-2fd7-431b-9755-66c0da679c8c",
   "metadata": {},
   "source": [
    "We will be making a 2 distribution to make the problem challenging \n",
    "\n",
    "A random force will be put to based on another normal distribution which will be also a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c9d0630-214a-424b-8306-becf95d72ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.1813139 , 2.86820261, 2.74745908, 2.01540672, 2.18937295])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars = 5\n",
    "means_velocity = np.random.normal(2 , 1 , cars)\n",
    "means_velocity# All have standard deviarion 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcad1103-742d-4920-8455-066782708f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cars = 5\n",
    "# means_force = np.random.normal(0.5 , 1 , cars)\n",
    "# means_force# All have standard deviarion 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b97ade50-f550-45a8-9fed-7e7ba99bfb5a",
   "metadata": {},
   "source": [
    "Each will run for around 1000 time steps after which the battery on the cars must be rechanrged. So we restard from time step 0. This cycle continues for over 2000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d5185b5-da89-4568-964e-a1be80202bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps = 1000\n",
    "iterations = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee28d828-993b-4fc2-ad68-842b2dd3d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = [5 , 5 , 5 , 5 , 5]\n",
    "N = [0 , 0 , 0 , 0 , 0]\n",
    "epsilon = 0.01 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90eec72-9a43-4ee2-84ca-4cd3f190ae17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_car(racecars , picked_car_number , velocity , total_timesteps_to_run_simulation):\n",
    "    \n",
    "    p.setJointMotorControlArray(racecars[picked_car_number], [2,3,5,7], p.VELOCITY_CONTROL,\n",
    "                                    targetVelocities =  [velocity for i in range(4)] , forces = [1,1,1,1])\n",
    "\n",
    "    for time_steps in range(total_timesteps_to_run_simulation):\n",
    "            p.stepSimulation()\n",
    "            if time_steps == total_timesteps_to_run_simulation-1:\n",
    "                basev = p.getBaseVelocity(racecars[picked_car_number])\n",
    "                reward = basev[0][0]#the reward is the cars base velocity which can be observed by the agent\n",
    "\n",
    "    return reward\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f0d3429-a796-486c-9b6e-a5fe0805b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Environment \n",
    "def get_velocity(picked_car):\n",
    "    # we need to pick the reward for a car ; \n",
    "    #we need two means one for the velocity of the joints of the car and one is a random force from a car. \n",
    "    '''\n",
    "    Parameters\n",
    "    ---------------------\n",
    "    picked_car - The index of the picked car\n",
    "\n",
    "    Returns \n",
    "    ---------------------\n",
    "    velocity - velocity of the joints of the car\n",
    "    force - external force added to the cars base.\n",
    "    '''\n",
    "    \n",
    "    applied_velocity = np.random.normal(means_velocity[picked_car] , 1 , 1)\n",
    "    \n",
    "    return applied_velocity[0] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68f2915d-44e5-4ff9-bf5f-e1b0d79db973",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decided by the agent \n",
    "def pick_car(Q,epsilon):#epsilon is the probablity here\n",
    "    pick = random.choices(['pick_max_car','pick_random'], weights=(1-epsilon,epsilon))\n",
    "    if pick[0]=='pick_max_car':\n",
    "        return Q.index(max(Q))\n",
    "    else:\n",
    "        max_car = Q.index(max(Q))\n",
    "        a = [0,1,2,3,4]\n",
    "        a.pop(max_car)\n",
    "        return random.choices(a, weights=(0.25,0.25,0.25,0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5a7d690-b688-4001-9b8c-bd99f9137fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def give_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8c1afce-2980-47a2-b95d-8e616b8aae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_timesteps_to_run_simulation = 10_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f850d4f5-9c6e-449d-b4f5-6f27ca1a6523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, b'base_link_joint', 4, -1, -1, 0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, b'chassis', (0.0, 0.0, 0.0), (0.0, 0.0, 0.05), (0.0, 0.0, 0.0, 1.0), -1)\n",
      "(1, b'chassis_inertia_joint', 4, -1, -1, 0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, b'chassis_inertia', (0.0, 0.0, 0.0), (0.0, 0.0, 0.0), (0.0, 0.0, 0.0, 1.0), 0)\n",
      "(2, b'left_rear_wheel_joint', 0, 7, 6, 1, 0.0, 0.0, 0.0, -1.0, 10.0, 100.0, b'left_rear_wheel', (0.0, 0.0, -1.0), (0.0, 0.1, 0.0), (-0.7071080798594737, 0.0, 0.0, 0.7071054825112363), 0)\n",
      "(3, b'right_rear_wheel_joint', 0, 8, 7, 1, 0.0, 0.0, 0.0, -1.0, 10.0, 100.0, b'right_rear_wheel', (0.0, 0.0, -1.0), (0.0, -0.1, 0.0), (-0.7071080798594737, 0.0, 0.0, 0.7071054825112363), 0)\n",
      "(4, b'left_steering_hinge_joint', 0, 9, 8, 1, 0.0, 0.0, -1.0, 1.0, 10.0, 100.0, b'left_steering_hinge', (-1.0, 0.0, 0.0), (0.325, 0.1, 0.0), (0.0, -0.7071080798594737, 0.0, 0.7071054825112363), 0)\n",
      "(5, b'left_front_wheel_joint', 0, 10, 9, 1, 0.0, 0.0, 0.0, -1.0, 10.0, 100.0, b'left_front_wheel', (0.0, 0.0, -1.0), (0.0, 0.0, 0.0), (-0.7071080798594737, 0.0, 0.0, 0.7071054825112363), 4)\n",
      "(6, b'right_steering_hinge_joint', 0, 11, 10, 1, 0.0, 0.0, -1.0, 1.0, 10.0, 100.0, b'right_steering_hinge', (-1.0, 0.0, 0.0), (0.325, -0.1, 0.0), (0.0, -0.7071080798594737, 0.0, 0.7071054825112363), 0)\n",
      "(7, b'right_front_wheel_joint', 0, 12, 11, 1, 0.0, 0.0, 0.0, -1.0, 10.0, 100.0, b'right_front_wheel', (0.0, 0.0, -1.0), (0.0, 0.0, 0.0), (-0.7071080798594737, 0.0, 0.0, 0.7071054825112363), 6)\n",
      "(8, b'hokuyo_joint', 4, -1, -1, 0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, b'laser', (0.0, 0.0, 0.0), (0.265, 0.0, 0.075), (0.0, 0.0, 0.0, 1.0), 0)\n",
      "(9, b'zed_camera_joint', 4, -1, -1, 0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, b'zed_camera_link', (0.0, 0.0, 0.0), (0.39, 0.0, 0.04), (0.0, 0.0, 0.0, 1.0), 0)\n",
      "(10, b'zed_camera_left_joint', 4, -1, -1, 0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, b'camera_link', (0.0, 0.0, 0.0), (0.0, 0.06, 0.0), (0.0, 0.0, 0.0, 1.0), 9)\n",
      "(11, b'zed_camera_right_joint', 4, -1, -1, 0, 0.0, 0.0, 0.0, -1.0, 0.0, 0.0, b'zed_camera_right_link', (0.0, 0.0, 0.0), (0.0, -0.06, 0.0), (0.0, 0.0, 0.0, 1.0), 9)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 58\u001b[0m\n\u001b[1;32m     55\u001b[0m     velocity \u001b[38;5;241m=\u001b[39m get_velocity(i)\n\u001b[1;32m     57\u001b[0m     N[i]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 58\u001b[0m     reward \u001b[38;5;241m=\u001b[39m \u001b[43mmove_car\u001b[49m\u001b[43m(\u001b[49m\u001b[43mracecars\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvelocity\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_timesteps_to_run_simulation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     Q[i] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ((reward \u001b[38;5;241m-\u001b[39m Q[i])\u001b[38;5;241m/\u001b[39mN[i])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m#Now we need to choose the best each time \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mmove_car\u001b[0;34m(racecars, picked_car_number, velocity, total_timesteps_to_run_simulation)\u001b[0m\n\u001b[1;32m      3\u001b[0m p\u001b[38;5;241m.\u001b[39msetJointMotorControlArray(racecars[picked_car_number], [\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m7\u001b[39m], p\u001b[38;5;241m.\u001b[39mVELOCITY_CONTROL,\n\u001b[1;32m      4\u001b[0m                                 targetVelocities \u001b[38;5;241m=\u001b[39m  [velocity \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m)] , forces \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m time_steps \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(total_timesteps_to_run_simulation):\n\u001b[0;32m----> 7\u001b[0m         \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstepSimulation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m time_steps \u001b[38;5;241m==\u001b[39m total_timesteps_to_run_simulation\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      9\u001b[0m             basev \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39mgetBaseVelocity(racecars[picked_car_number])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pybullet as p\n",
    "import time\n",
    "import numpy as np\n",
    "import pybullet_data\n",
    "\n",
    "epislon = 0.01 \n",
    "\n",
    "# random_pick = total_timesteps * epislon\n",
    "\n",
    "physicsClient = p.connect(p.GUI)\n",
    "p.setAdditionalSearchPath(pybullet_data.getDataPath())\n",
    "p.setGravity(0,0,-10)#or p.DIRECT for non-graphical version p.setAdditionalSearchPath(pybullet_data.getDataPath()) #optionally p.setGravity(0,0,-10)\n",
    "planeId = p.loadURDF(\"plane.urdf\")\n",
    "\n",
    "startPos1 = [0,2,0]\n",
    "startOrientation1 = p.getQuaternionFromEuler([0,0,0])\n",
    "racecar0 = p.loadURDF(\"/racecar/racecar.urdf\",startPos1, startOrientation1) #set the center of mass frame (loadURDF sets base link frame) \n",
    "p.resetBasePositionAndOrientation(racecar0, startPos1, startOrientation1)\n",
    "\n",
    "#car2\n",
    "startPos2 = [0,1,0]\n",
    "startOrientation2 = p.getQuaternionFromEuler([0,0,0])\n",
    "racecar1 = p.loadURDF(\"/racecar/racecar.urdf\",startPos2, startOrientation2) #set the center of mass frame (loadURDF sets base link frame) \n",
    "p.resetBasePositionAndOrientation(racecar1, startPos2, startOrientation2)\n",
    "\n",
    "\n",
    "startPos3 = [0,0,0]\n",
    "startOrientation3 = p.getQuaternionFromEuler([0,0,0])\n",
    "racecar2 = p.loadURDF(\"/racecar/racecar.urdf\",startPos3, startOrientation3) #set the center of mass frame (loadURDF sets base link frame) \n",
    "p.resetBasePositionAndOrientation(racecar2, startPos3, startOrientation3)\n",
    "\n",
    "\n",
    "\n",
    "startPos4 = [0,-1,0]\n",
    "startOrientation4 = p.getQuaternionFromEuler([0,0,0])\n",
    "racecar3 = p.loadURDF(\"/racecar/racecar.urdf\",startPos4, startOrientation4) #set the center of mass frame (loadURDF sets base link frame) \n",
    "p.resetBasePositionAndOrientation(racecar3, startPos4, startOrientation4)\n",
    "\n",
    "\n",
    "startPos5 = [0,-2,0]\n",
    "startOrientation5 = p.getQuaternionFromEuler([0,0,0])\n",
    "racecar4 = p.loadURDF(\"/racecar/racecar.urdf\",startPos5, startOrientation5) #set the center of mass frame (loadURDF sets base link frame) \n",
    "p.resetBasePositionAndOrientation(racecar4, startPos5, startOrientation5)\n",
    "\n",
    "numJoints = p.getNumJoints(racecar4)\n",
    "for joint in range(numJoints):\n",
    "  print(p.getJointInfo(racecar4, joint))\n",
    "\n",
    "p.setRealTimeSimulation(0)\n",
    "\n",
    "racecars = [racecar0 , racecar1 , racecar2 , racecar3 , racecar4]\n",
    "\n",
    "for i in range(10000):\n",
    "    if i < 5 : # We first explore all the possible options at least once \n",
    "        velocity = get_velocity(i)\n",
    "        \n",
    "        N[i]+=1\n",
    "        reward = move_car(racecars , i , velocity , total_timesteps_to_run_simulation)\n",
    "        \n",
    "        Q[i] += ((reward - Q[i])/N[i])\n",
    "\n",
    "    \n",
    "\n",
    "    else:\n",
    "        #Now we need to choose the best each time \n",
    "        \n",
    "        car_number = pick_car(Q,epsilon)\n",
    "        velocity = get_velocity(car_number)\n",
    "        N[car_number]+=1\n",
    "        \n",
    "        reward = move_car(racecars , picked_car_number , velocity , total_timesteps_to_run_simulation)\n",
    "        \n",
    "        Q[car_number] += ((reward - Q[car_number])/N[car_number])\n",
    "\n",
    "# for step in range(4000):\n",
    "#     p.stepSimulation()\n",
    "\n",
    "\n",
    "# # for i in range (10000):\n",
    "    \n",
    "    \n",
    "# # cubePos, cubeOrn = p.getBasePositionAndOrientation(boxId) \n",
    "# print(cubePos,cubeOrn)\n",
    "p.disconnect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92e1982f-652d-49a9-a4b6-db2ca14320af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.012312012245484283, 0.19786195493451686, 5, 5, 5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f04d1e-94c1-467f-a79c-93f8844ea446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to make a way to stop the car \n",
    "#we also need a way to incorporate resetiing the simulation to its start to continue it froim thew like in tthe book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3883c95-72f6-431b-b8e2-2915564b44b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
